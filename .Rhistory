fill=state)) +
geom_point(aes(color=state),
position = position_jitter(width = 0.07),
size = 0.6,
alpha = 0.65) +
geom_boxplot(width = 0.5, outlier.shape = NA, alpha = 0.25)+
scale_fill_manual(values=state_cols)+
scale_colour_manual(values=state_cols)+
scale_x_discrete(labels= c(
"rainforest\nspecialist",
"generalist",
"open-vegetation\nspecialist "
)
) +
xlab("habitat range") +
ylab(paste(param_symbol, y_axis_name, sep = " ") )+
theme(panel.background=element_rect(fill="white"),
panel.grid=element_line(colour=NULL),
panel.border=element_rect(fill=NA,colour="black"),
axis.title=element_text(size=10,face="bold"),
axis.text=element_text(size=8),
legend.position = "none")
### exporting directory
dir_out = "4_graphics/"
file_name = paste(trait_name, param_name, sep ="_")
# export plot
tiff(paste0(dir_out,file_name, ".tiff"),
units="cm", width=7, height=6.5, res=600)
print(plot_param)
dev.off()
### choose a trait!
trait_name = "height"
### import path
imp_path = paste0("2_trait_results/OUWIE/", trait_name)
### importing model fit
all_best_models = readRDS( paste0(imp_path, "/all_best_models.RDS"))
### importing model parameters
all_best_estimates =  readRDS( paste0(imp_path, "/all_best_estimates.RDS"))
### most frequent best fit
count_models = table(all_best_models$model)
most_freq_model = names(count_models)[count_models == max(count_models)]
most_freq_model
count_models
most_freq_model = names(count_models)[count_models == max(count_models)]
### vector w position of best fit
i_best = which(all_best_models$model == most_freq_model)
### select parameter estimates from most freq best model
freq_best_estimates = all_best_estimates[i_best]
### from list to df
est_df = data.frame( t( sapply(freq_best_estimates,c) ) )
apply(est_df, MARGIN = 2, mean)
apply(est_df, MARGIN = 2, mean)
apply(est_df, MARGIN = 2, sd)
### choose a trait!
trait_name = "sla"
### import path
imp_path = paste0("2_trait_results/OUWIE/", trait_name)
### importing model fit
all_best_models = readRDS( paste0(imp_path, "/all_best_models.RDS"))
### importing model parameters
all_best_estimates =  readRDS( paste0(imp_path, "/all_best_estimates.RDS"))
### most frequent best fit
count_models = table(all_best_models$model)
most_freq_model = names(count_models)[count_models == max(count_models)]
### vector w position of best fit
i_best = which(all_best_models$model == most_freq_model)
### select parameter estimates from most freq best model
freq_best_estimates = all_best_estimates[i_best]
### from list to df
est_df = data.frame( t( sapply(freq_best_estimates,c) ) )
apply(est_df, MARGIN = 2, mean)
apply(est_df, MARGIN = 2, sd)
count_models
clean_param_df
### describe
clean_param_df %>%
group_by(state) %>%
reframe(x = mean(estimate), SD = sd(estimate))
### choose a trait!
trait_name = "sla"
### import path
imp_path = paste0("2_trait_results/OUWIE/", trait_name)
### importing model fit
all_best_models = readRDS( paste0(imp_path, "/all_best_models.RDS"))
### importing model parameters
all_best_estimates =  readRDS( paste0(imp_path, "/all_best_estimates.RDS"))
### most frequent best fit
count_models = table(all_best_models$model)
most_freq_model = names(count_models)[count_models == max(count_models)]
### vector w position of best fit
i_best = which(all_best_models$model == most_freq_model)
### select parameter estimates from most freq best model
freq_best_estimates = all_best_estimates[i_best]
### from list to df
est_df = data.frame( t( sapply(freq_best_estimates,c) ) )
### pick one paramenter
param_name = "theta"
col_names = colnames(est_df)[grepl(param_name, colnames(est_df))]
est = est_df[col_names]
### organzing df
param_df = est %>%
pivot_longer(cols = any_of(col_names),
names_to = "state",
values_to = "estimate") %>%
mutate(
state = case_when(
grepl("_1", state) ~ "forest_specialist",
grepl("_2", state) ~ "generalist",
grepl("_3", state) ~ "open_specialist"
)
)
### outlier boundaries
med = median(param_df$estimate, na.rm = T)
bound= IQR(param_df$estimate, na.rm = T)*1.5
up_bound = med + bound
dw_bound = med - bound
### cleaning data
clean_param_df = param_df %>%
filter(estimate < up_bound & estimate > dw_bound)
### describe
clean_param_df %>%
group_by(state) %>%
reframe(x = mean(estimate), SD = sd(estimate))
### choose a trait!
trait_name = "height"
### import path
imp_path = paste0("2_trait_results/OUWIE/", trait_name)
### importing model fit
all_best_models = readRDS( paste0(imp_path, "/all_best_models.RDS"))
### importing model parameters
all_best_estimates =  readRDS( paste0(imp_path, "/all_best_estimates.RDS"))
### most frequent best fit
count_models = table(all_best_models$model)
most_freq_model = names(count_models)[count_models == max(count_models)]
### vector w position of best fit
i_best = which(all_best_models$model == most_freq_model)
### select parameter estimates from most freq best model
freq_best_estimates = all_best_estimates[i_best]
### from list to df
est_df = data.frame( t( sapply(freq_best_estimates,c) ) )
### pick one paramenter
param_name = "theta"
col_names = colnames(est_df)[grepl(param_name, colnames(est_df))]
est = est_df[col_names]
### organzing df
param_df = est %>%
pivot_longer(cols = any_of(col_names),
names_to = "state",
values_to = "estimate") %>%
mutate(
state = case_when(
grepl("_1", state) ~ "forest_specialist",
grepl("_2", state) ~ "generalist",
grepl("_3", state) ~ "open_specialist"
)
)
### outlier boundaries
med = median(param_df$estimate, na.rm = T)
bound= IQR(param_df$estimate, na.rm = T)*1.5
up_bound = med + bound
dw_bound = med - bound
### cleaning data
clean_param_df = param_df %>%
filter(estimate < up_bound & estimate > dw_bound)
### describe
clean_param_df %>%
group_by(state) %>%
reframe(x = mean(estimate), SD = sd(estimate))
### choose a trait!
trait_name = "seed"
### import path
imp_path = paste0("2_trait_results/OUWIE/", trait_name)
### importing model fit
all_best_models = readRDS( paste0(imp_path, "/all_best_models.RDS"))
### importing model parameters
all_best_estimates =  readRDS( paste0(imp_path, "/all_best_estimates.RDS"))
### most frequent best fit
count_models = table(all_best_models$model)
most_freq_model = names(count_models)[count_models == max(count_models)]
### vector w position of best fit
i_best = which(all_best_models$model == most_freq_model)
### select parameter estimates from most freq best model
freq_best_estimates = all_best_estimates[i_best]
### from list to df
est_df = data.frame( t( sapply(freq_best_estimates,c) ) )
### pick one paramenter
param_name = "theta"
col_names = colnames(est_df)[grepl(param_name, colnames(est_df))]
est = est_df[col_names]
### organzing df
param_df = est %>%
pivot_longer(cols = any_of(col_names),
names_to = "state",
values_to = "estimate") %>%
mutate(
state = case_when(
grepl("_1", state) ~ "forest_specialist",
grepl("_2", state) ~ "generalist",
grepl("_3", state) ~ "open_specialist"
)
)
### outlier boundaries
med = median(param_df$estimate, na.rm = T)
bound= IQR(param_df$estimate, na.rm = T)*1.5
up_bound = med + bound
dw_bound = med - bound
### cleaning data
clean_param_df = param_df %>%
filter(estimate < up_bound & estimate > dw_bound)
### describe
clean_param_df %>%
group_by(state) %>%
reframe(x = mean(estimate), SD = sd(estimate))
i_best
count_models
### libraries
if (!require("tidyverse")) install.packages("tidyverse"); library("tidyverse")
if (!require("ggplot2")) install.packages("ggplot2"); library("ggplot2")
if (!require("Hmisc")) install.packages("Hmisc"); library("Hmisc")
if (!require("PupillometryR")) install.packages("PupillometryR"); library("PupillometryR")
if (!require("plyr")) install.packages("plyr"); library("plyr")
if (!require("ape")) install.packages("ape"); library("ape")
### read data
habitat_mtx = read.table("0_data/habitat_matrix.csv",
h=T, sep=",", na.strings = "na")
### count habtiats
sort(apply(habitat_mtx[,-1], FUN = sum, MARGIN = 2))
### habitat names
habitat_names = habitat_mtx %>%
select(! species) %>%
colnames()
forest = c(
"Floresta_Ombrofila",
"Floresta_Ombrofila_Mista",
"Floresta_de_Terra_Firme",
"Floresta_Ciliar"
)
open = c(
"Afloramento_rochoso",
"Campinarana",
"Carrasco",
"Cerrado",
"Campo_de_Varzea",
"Campo_Rupestre",
"Restinga",
"Savana_Amazonica"
)
other = habitat_names[!habitat_names %in% c(forest, open)]
### presence per habitat
habitat_pres = habitat_mtx %>%
pivot_longer(cols = any_of(habitat_names),
names_to = "habitat",
values_to = "presence")
habitat_pres
View(habitat_mtx)
habitat_mtx %>%
filter(Cerrado == 1 |
Campo_Rupestre == 1|
Floresta_Ciliar == 1)
habitat_mtx %>%
filter(Cerrado == 1 |
Campo_Rupestre == 1)
habitat_mtx %>%
filter(Cerrado == 1 |
Campo_Rupestre == 1) %>%
select(species)
my_spp = habitat_mtx %>%
filter(Cerrado == 1 |
Campo_Rupestre == 1) %>%
select(species)
### loading trait data
trait_mtx = read.table("0_data/trait_matrix.csv",
h=T, sep=",", na.strings = "na")
### sampled species
sampled_sp = unique(trait_mtx$species)
### defininf states
spp_states = habitat_range$range
names(spp_states) = habitat_range$species
### loading phylogenetic tree
mcc_phylo = read.tree("0_data/pruned_mcc_phylo.nwk")
### counting pruned phylognetic trees
n_phylo = length(list.files("0_data/pruned_phylos"))
### loading occurrence count per domain
habitat_range = readRDS("1_habitat_results/habitat_range.RDS")
### loading trait data
trait_mtx = read.table("0_data/trait_matrix.csv",
h=T, sep=",", na.strings = "na")
### sampled species
sampled_sp = unique(trait_mtx$species)
### defininf states
spp_states = habitat_range$range
names(spp_states) = habitat_range$species
### trait values per species
spp_traits = trait_mtx %>%
group_by(species) %>%
reframe(height = mean(plant_height, na.rm=T) ,
sla =  mean(sla, na.rm=T) ,
seed = mean(seed_weight, na.rm=T) ,
n = n()
)
my_spp = habitat_mtx %>%
filter(Cerrado == 1 |
Campo_Rupestre == 1) %>%
select(species) %>%
pull()
spp_traits %>%
filter(species == my_spp)
my_spp
spp_traits %>%
filter(species %in% my_spp)
### choose a trait!
trait_name = "height"
### import path
imp_path = paste0("2_trait_results/OUWIE/", trait_name)
### importing model fit
all_best_models = readRDS( paste0(imp_path, "/all_best_models.RDS"))
### importing model parameters
all_best_estimates =  readRDS( paste0(imp_path, "/all_best_estimates.RDS"))
### most frequent best fit
count_models = table(all_best_models$model)
most_freq_model = names(count_models)[count_models == max(count_models)]
### vector w position of best fit
i_best = which(all_best_models$model == most_freq_model)
### select parameter estimates from most freq best model
freq_best_estimates = all_best_estimates[i_best]
### from list to df
est_df = data.frame( t( sapply(freq_best_estimates,c) ) )
### pick one paramenter
param_name = "sigma"
col_names = colnames(est_df)[grepl(param_name, colnames(est_df))]
est = est_df[col_names]
### organzing df
param_df = est %>%
pivot_longer(cols = any_of(col_names),
names_to = "state",
values_to = "estimate") %>%
mutate(
state = case_when(
grepl("_1", state) ~ "forest_specialist",
grepl("_2", state) ~ "generalist",
grepl("_3", state) ~ "open_specialist"
)
)
### outlier boundaries
med = median(param_df$estimate, na.rm = T)
bound= IQR(param_df$estimate, na.rm = T)*1.5
up_bound = med + bound
dw_bound = med - bound
### cleaning data
clean_param_df = param_df %>%
filter(estimate < up_bound & estimate > dw_bound)
### describe
clean_param_df %>%
group_by(state) %>%
reframe(x = mean(estimate), SD = sd(estimate))
13.7 - 3.84
9.86/3.84
13.7 - 2.95
10.75/2.95
### choose a trait!
trait_name = "sla"
### import path
imp_path = paste0("2_trait_results/OUWIE/", trait_name)
### importing model fit
all_best_models = readRDS( paste0(imp_path, "/all_best_models.RDS"))
### importing model parameters
all_best_estimates =  readRDS( paste0(imp_path, "/all_best_estimates.RDS"))
### most frequent best fit
count_models = table(all_best_models$model)
most_freq_model = names(count_models)[count_models == max(count_models)]
### vector w position of best fit
i_best = which(all_best_models$model == most_freq_model)
### select parameter estimates from most freq best model
freq_best_estimates = all_best_estimates[i_best]
### from list to df
est_df = data.frame( t( sapply(freq_best_estimates,c) ) )
### pick one paramenter
param_name = "sigma"
col_names = colnames(est_df)[grepl(param_name, colnames(est_df))]
est = est_df[col_names]
### organzing df
param_df = est %>%
pivot_longer(cols = any_of(col_names),
names_to = "state",
values_to = "estimate") %>%
mutate(
state = case_when(
grepl("_1", state) ~ "forest_specialist",
grepl("_2", state) ~ "generalist",
grepl("_3", state) ~ "open_specialist"
)
)
### outlier boundaries
med = median(param_df$estimate, na.rm = T)
bound= IQR(param_df$estimate, na.rm = T)*1.5
up_bound = med + bound
dw_bound = med - bound
### cleaning data
clean_param_df = param_df %>%
filter(estimate < up_bound & estimate > dw_bound)
### describe
clean_param_df %>%
group_by(state) %>%
reframe(x = mean(estimate), SD = sd(estimate))
clean_param_df
### choose a trait!
trait_name = "seed"
### import path
imp_path = paste0("2_trait_results/OUWIE/", trait_name)
### importing model fit
all_best_models = readRDS( paste0(imp_path, "/all_best_models.RDS"))
### importing model parameters
all_best_estimates =  readRDS( paste0(imp_path, "/all_best_estimates.RDS"))
### most frequent best fit
count_models = table(all_best_models$model)
most_freq_model = names(count_models)[count_models == max(count_models)]
### vector w position of best fit
i_best = which(all_best_models$model == most_freq_model)
### select parameter estimates from most freq best model
freq_best_estimates = all_best_estimates[i_best]
### from list to df
est_df = data.frame( t( sapply(freq_best_estimates,c) ) )
### pick one paramenter
param_name = "sigma"
col_names = colnames(est_df)[grepl(param_name, colnames(est_df))]
est = est_df[col_names]
### organzing df
param_df = est %>%
pivot_longer(cols = any_of(col_names),
names_to = "state",
values_to = "estimate") %>%
mutate(
state = case_when(
grepl("_1", state) ~ "forest_specialist",
grepl("_2", state) ~ "generalist",
grepl("_3", state) ~ "open_specialist"
)
)
### outlier boundaries
med = median(param_df$estimate, na.rm = T)
bound= IQR(param_df$estimate, na.rm = T)*1.5
up_bound = med + bound
dw_bound = med - bound
### cleaning data
clean_param_df = param_df %>%
filter(estimate < up_bound & estimate > dw_bound)
### describe
clean_param_df %>%
group_by(state) %>%
reframe(x = mean(estimate), SD = sd(estimate))
34.9-18
16.9/18
34.5/0.382
### importing Q values
param_list = readRDS("1_habitat_results/param_list.RDS")
### from list to df
param_df = data.frame( t( sapply(param_list,c) ) )
colnames(param_df) = colnames(param_list[[1]])
row.names(param_df) = NULL
param_df$model = colnames(sapply(param_list,c))
### most common best fit
tab_models = table(param_df$model)
best_model= names(tab_models[tab_models == max(tab_models)])
best_model
param_df
### pick one paramenter
param_name = "sigma"
### outlier boundaries
med = median(param_df[param_name], na.rm = T)
param_df
### pick one paramenter
param_name = "q12"
### outlier boundaries
med = median(param_df[param_name], na.rm = T)
param_df[param_name]
median(param_df[param_name], na.rm = T)
median(param_df[[param_name]], na.rm = T)
param_df[[param_name]]
pull(param_df[param_name])
c(param_df[param_name])
unlist(param_df[param_name])
### pick one paramenter
param_name = "q12"
param_vector = unlist(param_df[param_name])
### outlier boundaries
med = median(param_vector, na.rm = T)
bound= IQR(param_vector, na.rm = T)*1.5
up_bound = med + bound
dw_bound = med - bound
param_vector
### cleaning data
param_vector[param_vector < up_bound & param_vector > dw_bound]
### cleaning data
clean_param_vector = param_vector[param_vector < up_bound & param_vector > dw_bound]
### describe
mean(clean_param_vector), sd(clean_param_vector)
### describe
mean(clean_param_vector); sd(clean_param_vector)
### pick one paramenter
param_name = "q23"
param_vector = unlist(param_df[param_name])
### outlier boundaries
med = median(param_vector, na.rm = T)
bound= IQR(param_vector, na.rm = T)*1.5
up_bound = med + bound
dw_bound = med - bound
### cleaning data
clean_param_vector = param_vector[param_vector < up_bound & param_vector > dw_bound]
### describe
mean(clean_param_vector); sd(clean_param_vector)
1.82-0.23
1.82/0.23
